# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸŽ§ Orion Hub â€” Local Environment Configuration
# Voice + Web Gateway | Node-aware | GPU optional
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# --- Whisper Transcription Settings ---
# Model size options: tiny.en | base.en | small.en | medium.en | distil-medium.en | large-v3
WHISPER_MODEL_SIZE=distil-medium.en
WHISPER_DEVICE=cuda
WHISPER_COMPUTE_TYPE=float16

# --- LLM Model Selection ---
# Options: mistral | mixtral | other model aliases handled by brain
LLM_MODEL=mistral:instruct

# --- Cognitive Backends ---
# These are dynamically node-aware (resolved via ${PROJECT} from root .env)
BRAIN_URL=http://${PROJECT}-brain:8088
ORION_BUS_ENABLED=true
ORION_BUS_URL=redis://${PROJECT}-bus-core:6379/0

# --- Deployment Mode ---
# Controls which Caddyfile variant is mounted
MODE=dev
