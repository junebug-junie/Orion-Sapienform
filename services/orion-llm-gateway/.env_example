# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ§  Orion LLM Gateway â€” bus-native model client
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SERVICE_NAME=llm-gateway
SERVICE_VERSION=0.1.1

# Bus (usually already defined at project root, but safe to override here)
ORION_BUS_ENABLED=true
ORION_BUS_URL=redis://100.92.216.81:6379/0
HEARTBEAT_INTERVAL_SEC=10

# LLM gateway bus channels
CHANNEL_LLM_INTAKE=orion-exec:request:LLMGatewayService
CHANNEL_LLM_REPLY_PREFIX=orion:llm:reply

# Spark
CHANNEL_SPARK_INTROSPECT_CANDIDATE=orion:spark:introspect:candidate

# Backend endpoints
# atlas network backend
#ORION_LLM_VLLM_URL=http://orion-vllm-host:8000
# non-atlas backend
ORION_LLM_VLLM_URL=http://100.121.214.30:7005
# use atlas's tailscale IP for atlas
ORION_LLM_LLAMACPP_URL=http://orion-llamacpp-host:7005
#ORION_LLM_LLAMACPP_URL:http://100.121.214.30:7005

# Timeouts (seconds)
CONNECT_TIMEOUT_SEC=10
READ_TIMEOUT_SEC=300

# Service label in replies
ORION_LLM_SERVICE_NAME=LLMGatewayService

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ”§ LLM Profiles (vLLM routing)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Path *inside* the container where the profiles YAML will be mounted
LLM_PROFILES_CONFIG_PATH=/app/config/llm_profiles.yaml
LLM_DEFAULT_PROFILE_NAME=llama3-8b-instruct-q4km-athena-p4
#deepseek-70b-gguf-atlas
ORION_DEFAULT_LLM_MODEL=Active-GGUF-Model
ORION_LLM_DEFAULT_BACKEND=llamacpp
