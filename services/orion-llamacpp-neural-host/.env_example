SERVICE_NAME=orion-llamacpp-neural-host
SERVICE_VERSION=0.1.0
LLM_PROFILE_NAME=llama3-8b-instruct-q4km-athena-p4
LLM_PROFILES_CONFIG_PATH=/app/config/llm_profiles.yaml
HF_TOKEN=

# Optional overrides
LLAMACPP_MODEL_PATH_OVERRIDE=
LLAMACPP_N_GPU_LAYERS_OVERRIDE=
LLAMACPP_CTX_SIZE_OVERRIDE=
