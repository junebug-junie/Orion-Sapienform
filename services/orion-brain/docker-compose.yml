# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ§  Orion Brain â€” Cognitive Core
# Manages inference, routing, and event streams across the Mesh
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

services:
  brain:
    build:
      context: ../..
      dockerfile: services/orion-brain/Dockerfile
    image: ${PROJECT:-orion}-brain:latest
    container_name: ${PROJECT:-orion}-brain
    ports:
      - "${PORT:-8088}:8088"
    restart: unless-stopped
    environment:
      - SERVICE_NAME=${SERVICE_NAME}
      - SERVICE_VERSION=${SERVICE_VERSION}
      - PORT=${PORT}

      # --- Bus ---
      - ORION_BUS_ENABLED=${ORION_BUS_ENABLED}
      - ORION_BUS_URL=${ORION_BUS_URL}

      # --- LLM Backend Routing ---
      - BACKENDS=${BACKENDS}
      - SELECTION_POLICY=${SELECTION_POLICY}
      - HEALTH_INTERVAL_SEC=${HEALTH_INTERVAL_SEC}
      - CONNECT_TIMEOUT_SEC=${CONNECT_TIMEOUT_SEC}
      - READ_TIMEOUT_SEC=${READ_TIMEOUT_SEC}
      - REDIS_WAIT_ATTEMPTS=${REDIS_WAIT_ATTEMPTS}
      - REDIS_WAIT_DELAY=${REDIS_WAIT_DELAY}

      # --- Brain Channels ---
      - CHANNEL_BRAIN_INTAKE=${CHANNEL_BRAIN_INTAKE}
      - CHANNEL_BRAIN_OUT=${CHANNEL_BRAIN_OUT}
      - CHANNEL_BRAIN_STATUS=${CHANNEL_BRAIN_STATUS}
      - CHANNEL_BRAIN_STREAM=${CHANNEL_BRAIN_STREAM}

      # --- Dream Out ---
      - CHANNEL_DREAM_TRIGGER=${CHANNEL_DREAM_TRIGGER}

      # --- Voice / Collapse Hooks ---
      - CHANNEL_VOICE_TRANSCRIPT=${CHANNEL_VOICE_TRANSCRIPT}
      - CHANNEL_VOICE_LLM=${CHANNEL_VOICE_LLM}
      - CHANNEL_VOICE_TTS=${CHANNEL_VOICE_TTS}
      - CHANNEL_COLLAPSE_INTAKE=${CHANNEL_COLLAPSE_INTAKE}

      # --- GPU ---
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES}

    command: >
      /bin/sh -c "sleep ${STARTUP_DELAY:-5} &&
      python -m uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8088}"

    networks:
      app-net:
        aliases:
          - brain
          - ${PROJECT:-orion}-brain
          - llm-brain

  brain-llm:
    image: ollama/ollama:latest
    container_name: ${PROJECT:-orion}-brain-llm
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    dns:
      - 1.1.1.1
      - 8.8.8.8
    volumes:
      - ollama_data:/root/.ollama
      #- ./models:/models
    ports:
      - "11434:11434"
    restart: unless-stopped
    networks:
      app-net:
        aliases:
          - llm-brain

volumes:
  ollama_data:

networks:
  app-net:
    external: true
