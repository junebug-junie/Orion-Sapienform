# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ§  Orion LLM Gateway â€” bus-native model client
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SERVICE_NAME=llm-gateway
SERVICE_VERSION=0.1.0

# Bus (usually already defined at project root, but safe to override here)
ORION_BUS_ENABLED=true
ORION_BUS_URL=redis://100.92.216.81:6379/0

# LLM gateway bus channels
CHANNEL_LLM_INTAKE=orion-exec:request:LLMGatewayService
CHANNEL_LLM_REPLY_PREFIX=orion:llm:reply

# Backend endpoints
# atlas network backend
#ORION_LLM_VLLM_URL=http://orion-vllm:8000
# non-atlas backend
ORION_LLM_VLLM_URL=http://100.121.214.30:7000

# Timeouts (seconds)
CONNECT_TIMEOUT_SEC=10
READ_TIMEOUT_SEC=60

# Service label in replies
ORION_LLM_SERVICE_NAME=LLMGatewayService

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ðŸ”§ LLM Profiles (vLLM routing)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Path *inside* the container where the profiles YAML will be mounted
LLM_PROFILES_CONFIG_PATH=/app/config/llm_profiles.yaml
LLM_DEFAULT_PROFILE_NAME=mistral-7b-vllm
